import { OpenAIStream, StreamingTextResponse } from 'ai'
import OpenAI from 'openai'
import { searchProperties, createLead } from '@/lib/ai/tools'

// Configure OpenRouter client
const openai = new OpenAI({
    apiKey: process.env.OPENROUTER_API_KEY || '',
    baseURL: 'https://openrouter.ai/api/v1',
})

// Tool Definitions
const tools: OpenAI.Chat.Completions.ChatCompletionTool[] = [
    {
        type: 'function',
        function: {
            name: 'searchProperties',
            description: 'T√¨m ki·∫øm b·∫•t ƒë·ªông s·∫£n (nh√† ph·ªë, cƒÉn h·ªô, ƒë·∫•t n·ªÅn, d·ª± √°n) d·ª±a tr√™n t·ª´ kh√≥a, ƒë·ªãa ƒëi·ªÉm, nhu c·∫ßu.',
            parameters: {
                type: 'object',
                properties: {
                    query: {
                        type: 'string',
                        description: 'T·ª´ kh√≥a t√¨m ki·∫øm (v√≠ d·ª•: "cƒÉn h·ªô 2 ph√≤ng ng·ªß qu·∫≠n 1", "vinhomes grand park", "ƒë·∫•t n·ªÅn gi√° r·∫ª")',
                    },
                },
                required: ['query'],
            },
        },
    },
    {
        type: 'function',
        function: {
            name: 'createLead',
            description: 'L∆∞u th√¥ng tin li√™n h·ªá c·ªßa kh√°ch h√†ng khi h·ªç mu·ªën ƒë∆∞·ª£c t∆∞ v·∫•n k·ªπ h∆°n.',
            parameters: {
                type: 'object',
                properties: {
                    name: { type: 'string', description: 'T√™n kh√°ch h√†ng' },
                    phone: { type: 'string', description: 'S·ªë ƒëi·ªán tho·∫°i kh√°ch h√†ng' },
                    message: { type: 'string', description: 'L·ªùi nh·∫Øn ho·∫∑c nhu c·∫ßu c·ª• th·ªÉ' },
                },
                required: ['name', 'phone'],
            },
        },
    },
]

// System prompt
const systemPrompt = `B·∫°n l√† tr·ª£ l√Ω ·∫£o th√¥ng minh c·ªßa Happy Land - n·ªÅn t·∫£ng b·∫•t ƒë·ªông s·∫£n h√†ng ƒë·∫ßu Vi·ªát Nam.

NHI·ªÜM V·ª§:
- T∆∞ v·∫•n v·ªÅ c√°c d·ª± √°n b·∫•t ƒë·ªông s·∫£n (cƒÉn h·ªô, nh√† ph·ªë, ƒë·∫•t n·ªÅn).
- Gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ gi√° c·∫£, v·ªã tr√≠, ph√°p l√Ω.
- H·ªó tr·ª£ t√¨m ki·∫øm b·∫•t ƒë·ªông s·∫£n ph√π h·ª£p b·∫±ng c√¥ng c·ª• searchProperties.
- L∆∞u th√¥ng tin kh√°ch h√†ng b·∫±ng c√¥ng c·ª• createLead khi kh√°ch h√†ng cung c·∫•p t√™n v√† s·ªë ƒëi·ªán tho·∫°i.

QUY T·∫ÆC ƒê∆Ø·ªúNG D·∫™N (QUAN TR·ªåNG):
- Khi t√¨m th·∫•y b·∫•t ƒë·ªông s·∫£n, B·∫ÆT BU·ªòC ph·∫£i cung c·∫•p ƒë∆∞·ªùng d·∫´n d∆∞·ªõi d·∫°ng Markdown Link: [Ti√™u ƒë·ªÅ BƒêS](url).
- V√≠ d·ª•: "T√¥i t√¨m th·∫•y [CƒÉn h·ªô 2PN Vinhomes](/nha-dat/can-ho-2pn) ph√π h·ª£p v·ªõi b·∫°n."
- KH√îNG ƒë∆∞·ª£c hi·ªÉn th·ªã URL tr·∫ßn (nh∆∞ https://...).

PHONG C√ÅCH:
- Th√¢n thi·ªán, l·ªãch s·ª±, chuy√™n nghi·ªáp.
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, s√∫c t√≠ch.
- S·ª≠ d·ª•ng emoji ph√π h·ª£p üè†üí∞‚ú®.
- Lu√¥n h·ªèi th√¥ng tin c·ª• th·ªÉ ƒë·ªÉ t∆∞ v·∫•n t·ªët h∆°n.`

export async function POST(req: Request) {
    try {
        const { messages } = await req.json()

        if (!process.env.OPENROUTER_API_KEY) {
            return new Response('OpenRouter API key not configured', { status: 500 })
        }

        // Initial call to model
        const response = await openai.chat.completions.create({
            model: 'google/gemini-2.5-flash',
            messages: [
                { role: 'system', content: systemPrompt },
                ...messages
            ],
            tools,
            tool_choice: 'auto',
        })

        const responseMessage = response.choices[0].message

        // Handle Tool Calls
        if (responseMessage.tool_calls) {
            const toolCalls = responseMessage.tool_calls

            // Create a new messages array with the assistant's tool call message
            const newMessages = [
                { role: 'system', content: systemPrompt },
                ...messages,
                responseMessage
            ]

            // Execute tools
            for (const toolCall of toolCalls) {
                const functionName = toolCall.function.name
                const functionArgs = JSON.parse(toolCall.function.arguments)
                let functionResult = ''

                if (functionName === 'searchProperties') {
                    functionResult = await searchProperties(functionArgs.query)
                } else if (functionName === 'createLead') {
                    functionResult = await createLead(functionArgs.name, functionArgs.phone, functionArgs.message)
                }

                newMessages.push({
                    tool_call_id: toolCall.id,
                    role: 'tool',
                    name: functionName,
                    content: functionResult,
                })
            }

            // Second call to model with tool results
            const secondResponse = await openai.chat.completions.create({
                model: 'google/gemini-2.5-flash',
                stream: true,
                messages: newMessages as any,
            })

            const stream = OpenAIStream(secondResponse as any)
            return new StreamingTextResponse(stream)
        }

        // If no tool calls, just stream the response (but we need to stream it, the first response was not streamed)
        // So we need to make a streaming call if there were no tool calls.
        // Optimization: We could have started with stream: true, but handling tool calls in stream is harder with raw client.
        // Re-call with stream: true for the text response.

        const streamResponse = await openai.chat.completions.create({
            model: 'google/gemini-2.5-flash',
            stream: true,
            messages: [
                { role: 'system', content: systemPrompt },
                ...messages
            ],
            temperature: 0.7,
        })

        const stream = OpenAIStream(streamResponse as any)
        return new StreamingTextResponse(stream)

    } catch (error) {
        console.error('Chat API Error:', error)
        return new Response('Internal Server Error', { status: 500 })
    }
}
